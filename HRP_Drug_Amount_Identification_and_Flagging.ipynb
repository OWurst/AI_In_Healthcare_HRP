{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41074d57",
   "metadata": {},
   "source": [
    "# Drug Amount Identification\n",
    "For my HRP, I will be using AI tools to scrape medical notes to identify drug amounts administered to patients. If I can do this successfully, I will use these methods to flag discrepencies between drugs given to patients according to the prescriptions table, and the notes that have been written up on the patients. Flagging discrepencies for closer examination will help hospitals in the following ways:\n",
    "1. More accurately track inventory\n",
    "2. Identify common pain points in data entry\n",
    "3. Build more robust datasets to work with (less bad data)\n",
    "4. Treat patients more effectively (more accurate information on treatment a patient has already received)\n",
    "5. Identify potential fraud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96438580",
   "metadata": {},
   "source": [
    "## Setup and Data Exploration\n",
    "Create the database connection and identify common prescriptions so that we can work with a subset of the data and determine the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030c4caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mysql.connector\n",
    "import yaml\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import spacy\n",
    "import medspacy\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n",
    "from gpt4all import GPT4All\n",
    "from pathlib import Path\n",
    "import spacy\n",
    "from spacy.pipeline import EntityRuler\n",
    "import re\n",
    "import os\n",
    "from typing import List, Tuple, Any, Optional\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bf0057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load config file and connect to MySQL\n",
    "with open(\"config.yaml\", 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "conn = mysql.connector.connect(\n",
    "    host=config[\"mysql\"][\"host\"],\n",
    "    user=config[\"mysql\"][\"user\"],\n",
    "    password=config[\"mysql\"][\"password\"],\n",
    "    port=config[\"mysql\"].get(\"port\", 3306)\n",
    ")\n",
    "conn.database = \"healthcare_db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a93565a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_query(query):\n",
    "    try:    \n",
    "        conn.consume_results()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    cursor = conn.cursor(buffered=True)\n",
    "    try:\n",
    "        cursor.execute(query)\n",
    "        result = cursor.fetchall()\n",
    "        columns = [i[0] for i in cursor.description]\n",
    "        df = pd.DataFrame(result, columns=columns)\n",
    "    finally:\n",
    "        cursor.close()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163aba0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT\n",
    "  LOWER(COALESCE(DRUG_NAME_GENERIC, DRUG)) AS drug_name,\n",
    "  COUNT(*) AS prescription_count,\n",
    "  COUNT(DISTINCT SUBJECT_ID) AS patient_count\n",
    "FROM prescriptions\n",
    "GROUP BY drug_name\n",
    "ORDER BY prescription_count DESC\n",
    "LIMIT 10;\n",
    "\"\"\"\n",
    "\n",
    "prescription_count_df = execute_query(query)\n",
    "prescription_count_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ab4648",
   "metadata": {},
   "source": [
    "We will focus on these top drugs today. We will also need to map different names for these drugs so that we will be able to deal with hospital employees using different names for these drugs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2deb65bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query to see where raw != generic but generic is not null. Pairs should be unique.\n",
    "query = \"\"\"\n",
    "SELECT\n",
    "    LOWER(DRUG) AS drug_name,\n",
    "    LOWER(COALESCE(DRUG_NAME_GENERIC, DRUG)) AS generic_name,\n",
    "    DRUG AS raw_name\n",
    "FROM prescriptions\n",
    "GROUP BY drug_name, generic_name, raw_name\n",
    "ORDER BY drug_name;\n",
    "\"\"\"\n",
    "\n",
    "drug_name_mapping_df = execute_query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178d3a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the top generic name with the most raw names\n",
    "top_generic_name = drug_name_mapping_df.groupby('generic_name').size().idxmax()\n",
    "top_raw_names = drug_name_mapping_df[drug_name_mapping_df['generic_name'] == top_generic_name]['raw_name'].tolist()\n",
    "print(f\"Top generic name: {top_generic_name}\")\n",
    "print(f\"Raw names for {top_generic_name}: {', '.join(top_raw_names)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fdd7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) No two rows share the same raw_name\n",
    "print(drug_name_mapping_df['raw_name'].nunique() == len(drug_name_mapping_df))\n",
    "\n",
    "# 2) No missing values in either column\n",
    "print(drug_name_mapping_df['raw_name'].notna().all() and drug_name_mapping_df['generic_name'].notna().all())\n",
    "\n",
    "# 3) Each raw_name maps to exactly one generic_name\n",
    "print((drug_name_mapping_df.groupby('raw_name')['generic_name']\n",
    "          .nunique() == 1).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b288f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = drug_name_mapping_df.groupby('raw_name')['generic_name'].nunique()\n",
    "\n",
    "bad_raws = counts[counts > 1].index\n",
    "bad_cases = (\n",
    "    drug_name_mapping_df\n",
    "      .loc[drug_name_mapping_df['raw_name'].isin(bad_raws)]\n",
    "      .groupby('raw_name')['generic_name']\n",
    "      .apply(list)\n",
    "      .reset_index(name='generic_names')\n",
    ")\n",
    "\n",
    "print(bad_cases.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e9eae1",
   "metadata": {},
   "source": [
    "Ok, these many to many relationships are going to be a problem. Today we will ignore because we are going to focus on a subset of the drugs and ensure we have a model that can extract those and their amounts, but in the future we are going to have an issue that will have to be dealt with in the HRP. Hopefully we can get context clues for some and hopefully notes will largely specify say, which type of acetaminophen was administered, or give context clues that we can make a reasonable guess. If not, maybe it makes sense to just flag these as notation was not specific enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee67416f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find only the raw_names that map to exactly one generic\n",
    "many_to_one_raws = (\n",
    "    drug_name_mapping_df\n",
    "      .groupby('raw_name')['generic_name']\n",
    "      .nunique()\n",
    "      .loc[lambda s: s == 1]\n",
    "      .index\n",
    "      .tolist()\n",
    ")\n",
    "\n",
    "prescriptions = \", \".join(f\"'{r}'\" for r in many_to_one_raws)\n",
    "\n",
    "# 3) Query for the top 10 generics among those raws\n",
    "query = f\"\"\"\n",
    "SELECT\n",
    "  LOWER(COALESCE(DRUG_NAME_GENERIC, DRUG)) AS generic_name,\n",
    "  COUNT(*) AS prescription_count\n",
    "FROM prescriptions\n",
    "WHERE LOWER(DRUG) IN ({prescriptions})\n",
    "GROUP BY generic_name\n",
    "ORDER BY prescription_count DESC\n",
    "LIMIT 10;\n",
    "\"\"\"\n",
    "\n",
    "most_common_generics_df = execute_query(query)\n",
    "most_common_generics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74688fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_to_generic = dict(\n",
    "    zip(\n",
    "        drug_name_mapping_df['raw_name'],\n",
    "        drug_name_mapping_df['generic_name']\n",
    "    )\n",
    ")\n",
    "\n",
    "# for every raw name in the dictionary, add the lowercase version mapping to the same generic\n",
    "for raw_name in list(raw_to_generic.keys()):\n",
    "    generic_name = raw_to_generic[raw_name]\n",
    "    raw_to_generic[raw_name.lower()] = generic_name\n",
    "    raw_to_generic[raw_name.upper()] = generic_name\n",
    "\n",
    "# Quick sanity check: look at the first 10 mappings\n",
    "for raw, gen in list(raw_to_generic.items())[:10]:\n",
    "    print(f\"{raw} --> {gen}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb29e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query unique categories\n",
    "query = \"\"\"\n",
    "SELECT DISTINCT category\n",
    "FROM noteevents\n",
    "WHERE category IS NOT NULL AND category != '';\n",
    "\"\"\"\n",
    "\n",
    "execute_query(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50781395",
   "metadata": {},
   "source": [
    "Now we take 8 of our top 10 generics and query the notes that contain any of the raws, or the generic itself, of that generic. Why only 8? sw and ns will show up as part of a lot of words and be hard to search for. We will do one for the categories nursing, general, discharge, physician, pharmacy, and case management to quickly decide a category to focus on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd512a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_query(or_squence, category):\n",
    "  return f\"\"\"\n",
    "    SELECT\n",
    "      SUBJECT_ID,\n",
    "      HADM_ID,\n",
    "      CHARTDATE,\n",
    "      CATEGORY,\n",
    "      TEXT\n",
    "    FROM NOTEEVENTS\n",
    "    WHERE LOWER(TEXT) REGEXP '{or_squence}'\n",
    "    AND CATEGORY = '{category}'\n",
    "    LIMIT 1;\n",
    "    \"\"\"\n",
    "\n",
    "# drop sw and ns from the top generics\n",
    "most_common_generics_df = most_common_generics_df[\n",
    "    ~most_common_generics_df['generic_name'].isin(['sw', 'ns'])\n",
    "]\n",
    "top_gens = most_common_generics_df['generic_name'].tolist()\n",
    "\n",
    "search_terms = {\n",
    "    raw\n",
    "    for raw, gen in raw_to_generic.items()\n",
    "    if gen in top_gens\n",
    "} | set(top_gens)\n",
    "\n",
    "or_squence = \"|\".join(re.escape(term) for term in search_terms)\n",
    "\n",
    "notes_df = execute_query(build_query(or_squence, 'discharge summary'))\n",
    "print(f\"Found {len(notes_df)} matching notes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f895bd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_top10_drugs(text):\n",
    "    text_lower = text.lower()\n",
    "    found = {\n",
    "        raw_to_generic.get(term, term)\n",
    "        for term in search_terms\n",
    "        if term in text_lower\n",
    "    }\n",
    "    return list(found)\n",
    "\n",
    "def print_first_note(notes_df):\n",
    "    if not notes_df.empty:\n",
    "        first_note = notes_df.iloc[0]\n",
    "        print(f\"Top 10 drugs in note: {first_note['top10_drugs_in_note']}\")\n",
    "        print(f\"First note text: {first_note['TEXT']}\")\n",
    "    else:\n",
    "        print(\"No notes found.\")\n",
    "\n",
    "notes_df['top10_drugs_in_note'] = notes_df['TEXT'].apply(find_top10_drugs)\n",
    "\n",
    "print_first_note(notes_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8edff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "notes_df = execute_query(build_query(or_squence, 'Nursing/other'))\n",
    "notes_df['top10_drugs_in_note'] = notes_df['TEXT'].apply(find_top10_drugs)\n",
    "print_first_note(notes_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fadd248",
   "metadata": {},
   "outputs": [],
   "source": [
    "notes_df = execute_query(build_query(or_squence, 'Physician'))\n",
    "notes_df['top10_drugs_in_note'] = notes_df['TEXT'].apply(find_top10_drugs)\n",
    "\n",
    "print_first_note(notes_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0ad86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "notes_df = execute_query(build_query(or_squence, 'General'))\n",
    "notes_df['top10_drugs_in_note'] = notes_df['TEXT'].apply(find_top10_drugs)\n",
    "\n",
    "print_first_note(notes_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e998f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "notes_df = execute_query(build_query(or_squence, 'Pharmacy'))\n",
    "notes_df['top10_drugs_in_note'] = notes_df['TEXT'].apply(find_top10_drugs)\n",
    "\n",
    "print_first_note(notes_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5d29a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "notes_df = execute_query(build_query(or_squence, 'Case Management'))\n",
    "notes_df['top10_drugs_in_note'] = notes_df['TEXT'].apply(find_top10_drugs)\n",
    "\n",
    "print_first_note(notes_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09832e6",
   "metadata": {},
   "source": [
    "Using pharmacy notes, they are the clearest and look at a single drug."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf8edcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "SELECT\n",
    "    TEXT\n",
    "FROM NOTEEVENTS\n",
    "WHERE LOWER(TEXT) REGEXP '{or_squence}'\n",
    "AND CATEGORY = 'Pharmacy'\n",
    "LIMIT 1000;\n",
    "\"\"\"\n",
    "\n",
    "notes_df = execute_query(query)\n",
    "print(f\"Found {len(notes_df)} pharmacy notes matching the search terms.\")\n",
    "\n",
    "notes_df['top10_drugs_in_note'] = notes_df['TEXT'].apply(find_top10_drugs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb2b8c0",
   "metadata": {},
   "source": [
    "## Extraction:\n",
    "### Regex\n",
    "First, were gonna do some standard scraping. This is unlikely to work well, but it will provide a baseline that we will aim to beat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d964f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build generic to set of aliases map\n",
    "generic_aliases = defaultdict(set)\n",
    "for raw, gen in raw_to_generic.items():\n",
    "    generic_aliases[gen].add(raw)\n",
    "for gen in list(generic_aliases):\n",
    "    generic_aliases[gen].add(gen)\n",
    "\n",
    "# common dosage patterns regex\n",
    "unit_pattern   = r'(?:mg|g|mcg|μg|units|puffs)'\n",
    "number_pattern = r'(\\d+(?:\\.\\d+)?)'\n",
    "\n",
    "def extract_with_aliases(text, drug_list):\n",
    "    text_lower = text.lower()\n",
    "    extractions = []\n",
    "    for gen in drug_list:\n",
    "        for alias in generic_aliases[gen]:\n",
    "            esc = re.escape(alias)\n",
    "            p1 = re.compile(fr'{esc}.{{0,20}}?{number_pattern}\\s*{unit_pattern}', re.IGNORECASE)\n",
    "            p2 = re.compile(fr'{number_pattern}\\s*{unit_pattern}.{{0,20}}?{esc}', re.IGNORECASE)\n",
    "            for pat in (p1, p2):\n",
    "                for m in pat.finditer(text_lower):\n",
    "                    extractions.append({\n",
    "                        m.group(0).strip()\n",
    "                    })\n",
    "    return extractions\n",
    "\n",
    "notes_df['dosage_extractions'] = notes_df.apply(\n",
    "    lambda row: extract_with_aliases(row['TEXT'], row['top10_drugs_in_note']),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec33e84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Note 0\")\n",
    "print(notes_df.iloc[0]['top10_drugs_in_note'])\n",
    "print(f\"\\nExtractions: {notes_df.iloc[0]['dosage_extractions']}\\n\")\n",
    "print(notes_df.iloc[0]['TEXT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8c5e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Note 1\")\n",
    "print(notes_df.iloc[1]['top10_drugs_in_note'])\n",
    "print(f\"\\nExtractions: {notes_df.iloc[1]['dosage_extractions']}\\n\")\n",
    "print(notes_df.iloc[1]['TEXT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ac89fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Note 2\")\n",
    "print(notes_df.iloc[2]['top10_drugs_in_note'])\n",
    "print(f\"\\nExtractions: {notes_df.iloc[2]['dosage_extractions']}\\n\")\n",
    "print(notes_df.iloc[2]['TEXT'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a9d591",
   "metadata": {},
   "source": [
    "I'm actually pretty impressed with how well this has worked, but it is not very robust for several reasons:\n",
    "1. Using a window to extract a number will fail in cases where language is more complex and we are counting on getting lucky with the regex, our code may pick up the wrong number or no number at all\n",
    "2. We are able to get units, but something like 1000mg is very different from 1000mg hourly for 24 hours. For this to be useful for our goal, we need to be able to get these aggregations\n",
    "3. We have multiple differing extractions for certain entites, with no way to differentiate between them, crippling our ability to actually develop an automated system\n",
    "\n",
    "### Medspacy\n",
    "We need to improve upon this regex model of scraping. So lets use some nlp tools. I will be using medspacy to, using NER, to hopefully better understand this data and get more comprehensive extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0534de",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "ruler = nlp.add_pipe(\n",
    "    \"entity_ruler\",\n",
    "    before=\"ner\",\n",
    "    config={\"phrase_matcher_attr\": \"LOWER\"}\n",
    ")\n",
    "\n",
    "patterns = [{\"label\": \"DRUG\", \"pattern\": raw} for raw in raw_to_generic]\n",
    "ruler.add_patterns(patterns)\n",
    "\n",
    "unit_pat = r'(?:mg|g|mcg|μg|units|puffs)'\n",
    "num_pat  = r'(\\d+(?:\\.\\d+)?)'\n",
    "dosage_re = re.compile(fr'{num_pat}\\s*{unit_pat}', re.IGNORECASE)\n",
    "freq_re   = re.compile(\n",
    "    r'\\b(?:hourly|daily|bid|tid|qid|q\\d+h|every\\s+\\d+\\s+(?:hours?|days?))\\b',\n",
    "    re.IGNORECASE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387461da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_spacy(text):\n",
    "    doc = nlp(text)\n",
    "    meds = []\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ != \"DRUG\":\n",
    "            continue\n",
    "        span = ent.text\n",
    "        generic = raw_to_generic.get(span.lower(), span.lower())\n",
    "        if generic not in most_common_generics_df['generic_name'].tolist():\n",
    "            continue\n",
    "        \n",
    "        # still need a sliding window around the span for regex\n",
    "        start = max(ent.start_char - 50, 0)\n",
    "        end   = min(ent.end_char + 50, len(text))\n",
    "        window = text[start:end]\n",
    "        \n",
    "        dose_m = dosage_re.search(window)\n",
    "        if not dose_m:\n",
    "            continue\n",
    "        \n",
    "        freq_m = freq_re.search(window)\n",
    "        meds.append({\n",
    "            \"generic\":   generic,\n",
    "            \"matched\":   span,\n",
    "            \"strength\":  dose_m.group(0),\n",
    "            \"frequency\": freq_m.group(0) if freq_m else None\n",
    "        })\n",
    "    return meds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d85aa63",
   "metadata": {},
   "outputs": [],
   "source": [
    "notes_df['spacy_meds'] = notes_df['TEXT'].apply(extract_spacy)\n",
    "\n",
    "num = notes_df['spacy_meds'].apply(bool).sum()\n",
    "print(f\"Extracted meds from {num}/{len(notes_df)} notes\")\n",
    "for _, row in notes_df.head(5).iterrows():\n",
    "    print(row['spacy_meds'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9eac9c2",
   "metadata": {},
   "source": [
    "I'm dissapointed with how poorly this has worked. Compared to the last version, its outputs are a little better when they occur, but there are less attempts at an answer. Compared to our plain regex, we still have the sliding window and regex reliance which is not good, we still have the issue with repeat, differing drug outputs. The only improvement is that we sometimes have frequencies. This is not worth taking over the plain regex solution as is.\n",
    "\n",
    "### Llama\n",
    "The final model I will try will be a Llama model downloaded using gpt4all. This will have hardware performance issues compared to the last 2, but it will have far better memory and understanding across a text and should be able to far better label the drugs. We will create a reusable prompt and feed it in with the texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0ae010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_dir = Path(r\"D:\\gpt4all\\models\")  \n",
    "# model_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# model = GPT4All(\n",
    "#     model_name=\"Meta-Llama-3-8B-Instruct.Q4_0.gguf\",\n",
    "#     model_path=model_dir,\n",
    "#     allow_download=True,\n",
    "#     n_threads=4\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627cd3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_raws_in_text(generics, text):\n",
    "    text_lower = text.lower()\n",
    "    raws = []\n",
    "    for gen in generics:\n",
    "        for raw in generic_aliases.get(gen, []):\n",
    "            if raw in text_lower:\n",
    "                raws.append(raw)\n",
    "    return raws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1178b744",
   "metadata": {},
   "outputs": [],
   "source": [
    "notes_df['raws_in_note'] = notes_df.apply(\n",
    "    lambda row: find_raws_in_text(row['top10_drugs_in_note'], row['TEXT']),\n",
    "    axis=1\n",
    ")\n",
    "notes_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f5e95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def make_prompt(target_words, text):\n",
    "#     prompt = (\n",
    "#         \"You are a medical expert specializing in drug dosage extraction. \"\n",
    "#         \"Your task is to identify and extract the dosage information for the following drugs: \"\n",
    "#         f\"{', '.join(target_words)}.\\n\\n\"\n",
    "#         \"For each drug, provide the dosage in the format:\\n\"\n",
    "#         \"drug_name,dosage_value,unit,frequency\\n\"\n",
    "#         \"If a field is not present in the text, use 'None' for that field.\\n\\n\"\n",
    "#         \"Here is the text to analyze:\\n\"\n",
    "#         f\"{text}\\n\\n\"\n",
    "#         \"Return one line per drug.\"\n",
    "#     )\n",
    "#     return prompt\n",
    "\n",
    "# def extract_with_gpt4all(row, max_tokens=256):\n",
    "#     drugs = row[\"raws_in_note\"]\n",
    "#     if not drugs:\n",
    "#         return \"\"\n",
    "#     prompt = make_prompt(drugs, row[\"TEXT\"])\n",
    "\n",
    "#     response = model.generate(prompt, n_predict=max_tokens)\n",
    "#     return response.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96707790",
   "metadata": {},
   "source": [
    "#### No Memory, no gpu, shit computer\n",
    "I was not able to run this on my machine, so in Supplement_LLM.ipynb which is also attached with this assignment you can see how I got the prompted outputs from Llama. I ran supplement_LLM with a GPU in colab and copy and pasted the outputs below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e367a788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From GPU enabled environment: Supplement_LLM.ipynb\n",
    "output1 = \"(vancomycin,1000 mg,q48h)\"\n",
    "output2 = \"(methadone,20mg,q6h), (fentanyl,350mcg/hr,), (midazolam,10mg/hr,), (propofol,75mcg/kg/min,), (lorazepam,2mg,q4hr),(lorazepam,1mg,q4prn)\"\n",
    "output3 = \"(vancomycin,1 gram,q48h), (vancomycin,1 gram,PRN),(vancomycin,1 gram,when level <20 mcg/mL),(vancomycin,hold dose when level >20 mcg/mL)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4a2268",
   "metadata": {},
   "outputs": [],
   "source": [
    "note = notes_df.iloc[0]\n",
    "print(f\"Drugs in note: {note['raws_in_note']}\")\n",
    "print(output1)\n",
    "print(f\"text: {note['TEXT']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbdfaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "note = notes_df.iloc[1]\n",
    "print(f\"Drugs in note: {note['raws_in_note']}\")\n",
    "print(output2)\n",
    "print(f\"text: {note['TEXT']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c9ba87",
   "metadata": {},
   "outputs": [],
   "source": [
    "note = notes_df.iloc[2]\n",
    "print(f\"Drugs in note: {note['raws_in_note']}\")\n",
    "print(output2)\n",
    "print(f\"text: {note['TEXT']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02105a6d",
   "metadata": {},
   "source": [
    "This is by far the best of the options. It is smart enough to not output a bunch of copies of the same drug unless there is different for frequency or dosage and does a great job, to my eyes, of picking everything up accuracy. Also, there is no reliance on regex and sliding windows, which makes this method far more robust and transferrable to different types of documents and new drugs. Interestingly, the second option added correct information for drugs that weren't even in our list, which does tell me that I need to prompt more carefully, but also shows the model's potential to be generalized to my larger project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee2d402",
   "metadata": {},
   "source": [
    "## Citation\n",
    "\n",
    "@misc{gpt4all,\n",
    "  author = {Yuvanesh Anand and Zach Nussbaum and Brandon Duderstadt and Benjamin Schmidt and Andriy Mulyar},\n",
    "  title = {GPT4All: Training an Assistant-style Chatbot with Large Scale Data Distillation from GPT-3.5-Turbo},\n",
    "  year = {2023},\n",
    "  publisher = {GitHub},\n",
    "  journal = {GitHub repository},\n",
    "  howpublished = {\\url{https://github.com/nomic-ai/gpt4all}},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4082c4a2",
   "metadata": {},
   "source": [
    "## Flagging\n",
    "Now that we know what the best solution is for this extraction, we need to use this solution on all pharmacy notes with corresponding prescription entries so that we can make comparisons and begin flagging. For the real thing, I will take 1000 pharmacy noteevents and their corresponding prescription events, feed the notes into the pharmacy table, and compare extracted values from notes to prescription table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962ccad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_all_pharmacy_notes_and_perscriptions = \"\"\"\n",
    "WITH pharmacy_notes AS (\n",
    "  SELECT *\n",
    "  FROM NOTEEVENTS\n",
    "  WHERE CATEGORY = 'Pharmacy'\n",
    "  AND TEXT IS NOT NULL\n",
    "  LIMIT 1000\n",
    ")\n",
    "\n",
    "SELECT\n",
    "  n.ROW_ID AS note_row_id,\n",
    "  n.SUBJECT_ID,\n",
    "  n.HADM_ID,\n",
    "  n.CHARTDATE,\n",
    "  n.TEXT AS note_text,\n",
    "  p.ROW_ID AS prescription_row_id,\n",
    "  p.DRUG,\n",
    "  p.DRUG_NAME_GENERIC,\n",
    "  p.DRUG_TYPE,\n",
    "  p.PROD_STRENGTH,\n",
    "  p.DOSE_VAL_RX,\n",
    "  p.DOSE_UNIT_RX,\n",
    "  p.STARTDATE,\n",
    "  p.ENDDATE\n",
    "FROM pharmacy_notes n\n",
    "LEFT JOIN PRESCRIPTIONS p\n",
    "  ON n.SUBJECT_ID = p.SUBJECT_ID\n",
    "  AND n.HADM_ID = p.HADM_ID\n",
    "ORDER BY n.ROW_ID;\"\"\"\n",
    "\n",
    "full_table = execute_query(query_all_pharmacy_notes_and_perscriptions)\n",
    "full_table.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bb9ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_table.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e96bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv\n",
    "df_unique = full_table.drop_duplicates(subset='note_row_id')[['note_row_id', 'note_text']].copy()\n",
    "df_unique['note_text'] = df_unique['note_text'].str.replace('\"', \"'\", regex=False)\n",
    "df_unique['note_text'] = '\"' + df_unique['note_text'] + '\"'\n",
    "df_unique.to_csv('unique_pharmacy_notes.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02df303",
   "metadata": {},
   "source": [
    "Now read our extractions and get lists of tuples entered into a dict. To see the code for prompting the LLM, see HRP_Run_LLM.ipynb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a72c84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_token(token):\n",
    "    if token is None:\n",
    "        return None\n",
    "    token = str(token).strip().strip('\"').strip(\"'\")\n",
    "    if token == \"\" or token.lower() == \"none\":\n",
    "        return None\n",
    "    return token\n",
    "\n",
    "def extract_tuples_fuzzy(text: str):\n",
    "    \"\"\"\n",
    "    Extract tuples like (drug, dose, freq, ...) from free-form LLM text.\n",
    "    Works even if strings aren't quoted and multiple blocks exist.\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return []\n",
    "    \n",
    "    tuples_raw = re.findall(r\"\\(([^()]+)\\)\", text, flags=re.MULTILINE)\n",
    "\n",
    "    results = []\n",
    "    for t in tuples_raw:\n",
    "        parts = [p.strip() for p in t.split(\",\")]\n",
    "        if len(parts) > 4:\n",
    "            parts = parts[:3] + [\",\".join(parts[3:])]\n",
    "        while len(parts) < 4:\n",
    "            parts.append(None)\n",
    "\n",
    "        parts = [clean_token(p) for p in parts]\n",
    "        if any(p is not None for p in parts):\n",
    "            results.append(tuple(parts))\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f34d5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"extracted_pharmacy_notes.csv\")\n",
    "\n",
    "row_to_extraction = {}\n",
    "for _, row in df.iterrows():\n",
    "    note_id = row[\"note_row_id\"]\n",
    "    ext_text = row.get(\"extraction\", \"\")\n",
    "    parsed = extract_tuples_fuzzy(ext_text)\n",
    "    row_to_extraction[note_id] = parsed\n",
    "\n",
    "df[\"extraction_parsed\"] = df[\"extraction\"].apply(extract_tuples_fuzzy)\n",
    "print(row_to_extraction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16a76e6",
   "metadata": {},
   "source": [
    "Now we have our extractions, lets flag rows with missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553a4af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "_MASS_UNITS = {\n",
    "    \"mcg\": \"mcg\", \"μg\": \"mcg\", \"ug\": \"mcg\", \"microgram\": \"mcg\", \"micrograms\": \"mcg\",\n",
    "    \"mg\": \"mg\", \"milligram\": \"mg\", \"milligrams\": \"mg\",\n",
    "    \"g\": \"g\", \"gm\": \"g\", \"gram\": \"g\", \"grams\": \"g\"\n",
    "}\n",
    "\n",
    "def parse_mass(text):\n",
    "    \"\"\"Extract (value_float, unit_canonical) from a string like '50 mcg/hr'.\n",
    "       Ignores frequency/rate. Returns (None, None) if not found.\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return None, None\n",
    "    s = text.strip().lower()\n",
    "    m = re.search(r'(\\d+(?:\\.\\d+)?)', s)\n",
    "    if not m:\n",
    "        return None, None\n",
    "    val = float(m.group(1))\n",
    "    after = s[m.end():]\n",
    "    for tok in re.findall(r'[a-z]+', after):\n",
    "        if tok in _MASS_UNITS:\n",
    "            return val, _MASS_UNITS[tok]\n",
    "    before = s[:m.start()]\n",
    "    for tok in reversed(re.findall(r'[a-z]+', before)):\n",
    "        if tok in _MASS_UNITS:\n",
    "            return val, _MASS_UNITS[tok]\n",
    "    return None, None\n",
    "\n",
    "DRUG_SYNONYMS = {\"versed\": \"midazolam\", \"zyprexa\": \"olanzapine\"}\n",
    "\n",
    "def norm_str(s):\n",
    "    return str(s).strip().lower() if isinstance(s, str) else None\n",
    "\n",
    "def canonical_drug(name):\n",
    "    n = norm_str(name)\n",
    "    return DRUG_SYNONYMS.get(n, n)\n",
    "\n",
    "def normalize_text(s: str) -> str:\n",
    "    s = s.lower()\n",
    "    s = re.sub(r\"[^a-z0-9]+\", \" \", s)\n",
    "    return f\" {s.strip()} \"\n",
    "\n",
    "def drug_matches(drug_can: str, rx_row) -> bool:\n",
    "    \"\"\"Exact canonical OR word-boundary substring match in DRUG/DRUG_NAME_GENERIC.\"\"\"\n",
    "    if not drug_can:\n",
    "        return False\n",
    "    if rx_row.get(\"drug_norm\") == drug_can:\n",
    "        return True\n",
    "    if rx_row.get(\"drug_generic_norm\") == drug_can:\n",
    "        return True\n",
    "    needle = f\" {drug_can} \"\n",
    "    for col in (\"DRUG\", \"DRUG_NAME_GENERIC\"):\n",
    "        txt = rx_row.get(col)\n",
    "        if isinstance(txt, str) and needle in normalize_text(txt):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def doses_equal(val_a, unit_a, val_b, unit_b, tol=1e-6):\n",
    "    \"\"\"Require same mass unit + numeric equality (tiny tolerance).\"\"\"\n",
    "    if unit_a is None or unit_b is None:\n",
    "        return False\n",
    "    if unit_a != unit_b:\n",
    "        return False\n",
    "    if val_a is None or val_b is None:\n",
    "        return False\n",
    "    return abs(float(val_a) - float(val_b)) <= tol\n",
    "\n",
    "def ensure_list(obj):\n",
    "    if isinstance(obj, list):\n",
    "        return obj\n",
    "    try:\n",
    "        import ast\n",
    "        return ast.literal_eval(obj)\n",
    "    except Exception:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b220796",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"extraction_parsed\"] = df[\"extraction_parsed\"].apply(ensure_list)\n",
    "df[\"note_row_id\"] = df[\"note_row_id\"].astype(int)\n",
    "full_table[\"note_row_id\"] = full_table[\"note_row_id\"].astype(int)\n",
    "\n",
    "full_table[\"drug_norm\"] = full_table[\"DRUG\"].apply(canonical_drug)\n",
    "full_table[\"drug_generic_norm\"] = (\n",
    "    full_table[\"DRUG_NAME_GENERIC\"].apply(canonical_drug)\n",
    "    if \"DRUG_NAME_GENERIC\" in full_table.columns else None\n",
    ")\n",
    "\n",
    "def unit_from_dose_unit_norm(u):\n",
    "    \"\"\"dose_unit_norm may be things like 'mg', 'mcg', or 'mg/hr'. Keep mass unit only.\"\"\"\n",
    "    if not isinstance(u, str):\n",
    "        return None\n",
    "    _, mass = parse_mass(f\"1 {u}\")\n",
    "    return mass\n",
    "\n",
    "def compute_rx_val_unit_final(row):\n",
    "    if \"rx_val\" in row and \"rx_unit\" in row:\n",
    "        rv, ru = row[\"rx_val\"], row[\"rx_unit\"]\n",
    "        if pd.notna(rv) and isinstance(ru, str):\n",
    "            if ru in _MASS_UNITS:\n",
    "                return float(rv), ru\n",
    "            else:\n",
    "                ru_mass = unit_from_dose_unit_norm(ru)\n",
    "                if ru_mass:\n",
    "                    return float(rv), ru_mass\n",
    "\n",
    "    if \"dose_val_norm\" in row and \"dose_unit_norm\" in row:\n",
    "        dv, du = row[\"dose_val_norm\"], row[\"dose_unit_norm\"]\n",
    "        if pd.notna(dv) and du is not None:\n",
    "            du_mass = unit_from_dose_unit_norm(du)\n",
    "            if du_mass:\n",
    "                return float(dv), du_mass\n",
    "\n",
    "    ps = row.get(\"PROD_STRENGTH\")\n",
    "    vv, uu = parse_mass(ps) if isinstance(ps, str) else (None, None)\n",
    "    if vv is not None and uu is not None:\n",
    "        return vv, uu\n",
    "\n",
    "    vv, uu = parse_mass(row.get(\"DRUG\")) if isinstance(row.get(\"DRUG\"), str) else (None, None)\n",
    "    if vv is not None and uu is not None:\n",
    "        return vv, uu\n",
    "\n",
    "    vv, uu = parse_mass(row.get(\"DRUG_NAME_GENERIC\")) if isinstance(row.get(\"DRUG_NAME_GENERIC\"), str) else (None, None)\n",
    "    if vv is not None and uu is not None:\n",
    "        return vv, uu\n",
    "\n",
    "    return None, None\n",
    "\n",
    "rx_final = full_table.apply(compute_rx_val_unit_final, axis=1, result_type=\"reduce\")\n",
    "full_table[\"rx_val_final\"]  = [p[0] for p in rx_final]\n",
    "full_table[\"rx_unit_final\"] = [p[1] for p in rx_final]\n",
    "\n",
    "print(\n",
    "    \"Usable Rx dose/units:\",\n",
    "    int(full_table[\"rx_val\"].notna().sum() if \"rx_val\" in full_table.columns else 0), \"(rx_val) ->\",\n",
    "    int(full_table[\"rx_val_final\"].notna().sum()), \"(after fallbacks)\"\n",
    ")\n",
    "\n",
    "rx_by_note = {k: g for k, g in full_table.groupby(\"note_row_id\")}\n",
    "\n",
    "rows = []\n",
    "for _, r in df.iterrows():\n",
    "    nid = int(r[\"note_row_id\"])\n",
    "    tuples = r.get(\"extraction_parsed\", []) or []\n",
    "    rxg = rx_by_note.get(nid, pd.DataFrame())\n",
    "\n",
    "    for idx, t in enumerate(tuples):\n",
    "        drug = t[0] if len(t) > 0 else None\n",
    "        dose_raw = t[1] if len(t) > 1 else None\n",
    "\n",
    "        drug_can = canonical_drug(drug)\n",
    "        ex_val, ex_unit = parse_mass(dose_raw)\n",
    "\n",
    "        matched = False\n",
    "        drug_expected = None\n",
    "        rx_val_match = None\n",
    "        rx_unit_match = None\n",
    "\n",
    "        if drug_can and ex_val is not None and ex_unit is not None and not rxg.empty:\n",
    "            cand = rxg[rxg.apply(lambda rr: drug_matches(drug_can, rr), axis=1)]\n",
    "            if not cand.empty:\n",
    "                for _, rx in cand.iterrows():\n",
    "                    if doses_equal(ex_val, ex_unit, rx[\"rx_val_final\"], rx[\"rx_unit_final\"]):\n",
    "                        matched = True\n",
    "                        drug_expected = (\n",
    "                            rx[\"DRUG_NAME_GENERIC\"] if isinstance(rx.get(\"DRUG_NAME_GENERIC\"), str)\n",
    "                            else rx[\"DRUG\"]\n",
    "                        )\n",
    "                        rx_val_match = rx[\"rx_val_final\"]\n",
    "                        rx_unit_match = rx[\"rx_unit_final\"]\n",
    "                        break\n",
    "\n",
    "        rows.append({\n",
    "            \"note_row_id\": nid,\n",
    "            \"tuple_index\": idx,\n",
    "            \"drug_extracted\": drug,\n",
    "            \"dose_raw\": dose_raw,\n",
    "            \"dose_val_extracted\": ex_val,\n",
    "            \"dose_unit_extracted\": ex_unit,\n",
    "            \"drug_expected\": drug_expected,\n",
    "            \"rx_val_matched\": rx_val_match,\n",
    "            \"rx_unit_matched\": rx_unit_match,\n",
    "            \"matches_prescription\": bool(matched),\n",
    "        })\n",
    "\n",
    "results = pd.DataFrame(rows)\n",
    "matches_df = results[results[\"matches_prescription\"]].reset_index(drop=True)\n",
    "mismatches_df = results[~results[\"matches_prescription\"]].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591fefad",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa8b69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mismatches_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d390de2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82694b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "mismatches_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1701593",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_table.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb30b87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_table[full_table['note_row_id'] == 314570]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e92d25",
   "metadata": {},
   "source": [
    "Failing because my mysql data is not complete, going back to the roots with PRESCRIPTIONS.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e326d128",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_pharmacy_notes = \"\"\"\n",
    "SELECT\n",
    "  ROW_ID   AS note_row_id,\n",
    "  SUBJECT_ID,\n",
    "  HADM_ID,\n",
    "  CHARTDATE,\n",
    "  TEXT     AS note_text\n",
    "FROM NOTEEVENTS\n",
    "WHERE CATEGORY = 'Pharmacy'\n",
    "  AND TEXT IS NOT NULL\n",
    "ORDER BY ROW_ID\n",
    "LIMIT 1000;\n",
    "\"\"\"\n",
    "\n",
    "notes_df = execute_query(query_pharmacy_notes)\n",
    "print(\"Notes shape:\", notes_df.shape)\n",
    "\n",
    "def to_key_str(series: pd.Series) -> pd.Series:\n",
    "    if pd.api.types.is_integer_dtype(series):\n",
    "        return series.astype(\"Int64\").astype(str)\n",
    "    return series.astype(str)\n",
    "\n",
    "notes_df[\"SUBJECT_ID\"] = to_key_str(notes_df[\"SUBJECT_ID\"])\n",
    "notes_df[\"HADM_ID\"]    = to_key_str(notes_df[\"HADM_ID\"])\n",
    "\n",
    "notes_pairs = (\n",
    "    notes_df[[\"SUBJECT_ID\", \"HADM_ID\"]]\n",
    "    .dropna()\n",
    "    .drop_duplicates()\n",
    ")\n",
    "pairs_key = set(map(tuple, notes_pairs.values.tolist()))\n",
    "print(\"Unique (SUBJECT_ID, HADM_ID) pairs in notes:\", len(pairs_key))\n",
    "\n",
    "usecols = [\n",
    "    \"ROW_ID\", \"SUBJECT_ID\", \"HADM_ID\",\n",
    "    \"DRUG\", \"DRUG_NAME_GENERIC\", \"DRUG_TYPE\",\n",
    "    \"PROD_STRENGTH\", \"DOSE_VAL_RX\", \"DOSE_UNIT_RX\",\n",
    "    \"STARTDATE\", \"ENDDATE\",\n",
    "]\n",
    "\n",
    "chunksize = 250_000\n",
    "kept_chunks = []\n",
    "\n",
    "reader = pd.read_csv(\n",
    "    \"prescriptions.csv\",\n",
    "    usecols=usecols,\n",
    "    dtype={\"SUBJECT_ID\": str, \"HADM_ID\": str},\n",
    "    chunksize=chunksize,\n",
    "    low_memory=True\n",
    ")\n",
    "\n",
    "total_rows = 0\n",
    "kept_rows = 0\n",
    "for i, chunk in enumerate(reader, start=1):\n",
    "    total_rows += len(chunk)\n",
    "\n",
    "    chunk[\"SUBJECT_ID\"] = to_key_str(chunk[\"SUBJECT_ID\"])\n",
    "    chunk[\"HADM_ID\"]    = to_key_str(chunk[\"HADM_ID\"])\n",
    "\n",
    "    mask = chunk.apply(lambda r: (r[\"SUBJECT_ID\"], r[\"HADM_ID\"]) in pairs_key, axis=1)\n",
    "    filtered = chunk[mask]\n",
    "    kept_rows += len(filtered)\n",
    "\n",
    "    if not filtered.empty:\n",
    "        kept_chunks.append(filtered)\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        print(f\"Processed ~{i * chunksize:,} rows; kept so far: {kept_rows:,}\")\n",
    "\n",
    "rx_df_small = pd.concat(kept_chunks, ignore_index=True) if kept_chunks else pd.DataFrame(columns=usecols)\n",
    "print(\"Prescriptions total rows scanned:\", f\"{total_rows:,}\")\n",
    "print(\"Prescriptions kept (matching pairs):\", rx_df_small.shape)\n",
    "\n",
    "full_table = notes_df.merge(\n",
    "    rx_df_small,\n",
    "    on=[\"SUBJECT_ID\", \"HADM_ID\"],\n",
    "    how=\"left\",\n",
    "    suffixes=(\"\", \"_rx\")\n",
    ")\n",
    "\n",
    "full_table = full_table.rename(columns={\"ROW_ID\": \"prescription_row_id\"})\n",
    "\n",
    "desired_order = [\n",
    "    \"note_row_id\", \"SUBJECT_ID\", \"HADM_ID\", \"CHARTDATE\", \"note_text\",\n",
    "    \"prescription_row_id\", \"DRUG\", \"DRUG_NAME_GENERIC\", \"DRUG_TYPE\",\n",
    "    \"PROD_STRENGTH\", \"DOSE_VAL_RX\", \"DOSE_UNIT_RX\", \"STARTDATE\", \"ENDDATE\"\n",
    "]\n",
    "\n",
    "cols = [c for c in desired_order if c in full_table.columns] + \\\n",
    "       [c for c in full_table.columns if c not in desired_order]\n",
    "full_table = full_table[cols]\n",
    "\n",
    "print(\"Joined shape:\", full_table.shape)\n",
    "display(full_table.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef36217b",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_table.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b284c833",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"extraction_parsed\"] = df[\"extraction_parsed\"].apply(ensure_list)\n",
    "df[\"note_row_id\"] = df[\"note_row_id\"].astype(int)\n",
    "full_table[\"note_row_id\"] = full_table[\"note_row_id\"].astype(int)\n",
    "\n",
    "full_table[\"drug_norm\"] = full_table[\"DRUG\"].apply(canonical_drug)\n",
    "full_table[\"drug_generic_norm\"] = (\n",
    "    full_table[\"DRUG_NAME_GENERIC\"].apply(canonical_drug)\n",
    "    if \"DRUG_NAME_GENERIC\" in full_table.columns else None\n",
    ")\n",
    "\n",
    "def unit_from_dose_unit_norm(u):\n",
    "    \"\"\"dose_unit_norm may be things like 'mg', 'mcg', or 'mg/hr'. Keep mass unit only.\"\"\"\n",
    "    if not isinstance(u, str):\n",
    "        return None\n",
    "    _, mass = parse_mass(f\"1 {u}\")\n",
    "    return mass\n",
    "\n",
    "def compute_rx_val_unit_final(row):\n",
    "    if \"rx_val\" in row and \"rx_unit\" in row:\n",
    "        rv, ru = row[\"rx_val\"], row[\"rx_unit\"]\n",
    "        if pd.notna(rv) and isinstance(ru, str):\n",
    "            if ru in _MASS_UNITS:\n",
    "                return float(rv), ru\n",
    "            else:\n",
    "                ru_mass = unit_from_dose_unit_norm(ru)\n",
    "                if ru_mass:\n",
    "                    return float(rv), ru_mass\n",
    "\n",
    "    if \"dose_val_norm\" in row and \"dose_unit_norm\" in row:\n",
    "        dv, du = row[\"dose_val_norm\"], row[\"dose_unit_norm\"]\n",
    "        if pd.notna(dv) and du is not None:\n",
    "            du_mass = unit_from_dose_unit_norm(du)\n",
    "            if du_mass:\n",
    "                return float(dv), du_mass\n",
    "\n",
    "    ps = row.get(\"PROD_STRENGTH\")\n",
    "    vv, uu = parse_mass(ps) if isinstance(ps, str) else (None, None)\n",
    "    if vv is not None and uu is not None:\n",
    "        return vv, uu\n",
    "\n",
    "    vv, uu = parse_mass(row.get(\"DRUG\")) if isinstance(row.get(\"DRUG\"), str) else (None, None)\n",
    "    if vv is not None and uu is not None:\n",
    "        return vv, uu\n",
    "\n",
    "    vv, uu = parse_mass(row.get(\"DRUG_NAME_GENERIC\")) if isinstance(row.get(\"DRUG_NAME_GENERIC\"), str) else (None, None)\n",
    "    if vv is not None and uu is not None:\n",
    "        return vv, uu\n",
    "\n",
    "    return None, None\n",
    "\n",
    "rx_final = full_table.apply(compute_rx_val_unit_final, axis=1, result_type=\"reduce\")\n",
    "full_table[\"rx_val_final\"]  = [p[0] for p in rx_final]\n",
    "full_table[\"rx_unit_final\"] = [p[1] for p in rx_final]\n",
    "\n",
    "print(\n",
    "    \"Usable Rx dose/units:\",\n",
    "    int(full_table[\"rx_val\"].notna().sum() if \"rx_val\" in full_table.columns else 0), \"(rx_val) ->\",\n",
    "    int(full_table[\"rx_val_final\"].notna().sum()), \"(after fallbacks)\"\n",
    ")\n",
    "\n",
    "rx_by_note = {k: g for k, g in full_table.groupby(\"note_row_id\")}\n",
    "\n",
    "rows = []\n",
    "for _, r in df.iterrows():\n",
    "    nid = int(r[\"note_row_id\"])\n",
    "    tuples = r.get(\"extraction_parsed\", []) or []\n",
    "    rxg = rx_by_note.get(nid, pd.DataFrame())\n",
    "\n",
    "    for idx, t in enumerate(tuples):\n",
    "        drug = t[0] if len(t) > 0 else None\n",
    "        dose_raw = t[1] if len(t) > 1 else None\n",
    "\n",
    "        drug_can = canonical_drug(drug)\n",
    "        ex_val, ex_unit = parse_mass(dose_raw)\n",
    "\n",
    "        matched = False\n",
    "        drug_expected = None\n",
    "        rx_val_match = None\n",
    "        rx_unit_match = None\n",
    "\n",
    "        if drug_can and ex_val is not None and ex_unit is not None and not rxg.empty:\n",
    "            cand = rxg[rxg.apply(lambda rr: drug_matches(drug_can, rr), axis=1)]\n",
    "            if not cand.empty:\n",
    "                for _, rx in cand.iterrows():\n",
    "                    if doses_equal(ex_val, ex_unit, rx[\"rx_val_final\"], rx[\"rx_unit_final\"]):\n",
    "                        matched = True\n",
    "                        drug_expected = (\n",
    "                            rx[\"DRUG_NAME_GENERIC\"] if isinstance(rx.get(\"DRUG_NAME_GENERIC\"), str)\n",
    "                            else rx[\"DRUG\"]\n",
    "                        )\n",
    "                        rx_val_match = rx[\"rx_val_final\"]\n",
    "                        rx_unit_match = rx[\"rx_unit_final\"]\n",
    "                        break\n",
    "\n",
    "        rows.append({\n",
    "            \"note_row_id\": nid,\n",
    "            \"tuple_index\": idx,\n",
    "            \"drug_extracted\": drug,\n",
    "            \"dose_raw\": dose_raw,\n",
    "            \"dose_val_extracted\": ex_val,\n",
    "            \"dose_unit_extracted\": ex_unit,\n",
    "            \"drug_expected\": drug_expected,\n",
    "            \"rx_val_matched\": rx_val_match,\n",
    "            \"rx_unit_matched\": rx_unit_match,\n",
    "            \"matches_prescription\": bool(matched),\n",
    "        })\n",
    "\n",
    "results = pd.DataFrame(rows)\n",
    "matches_df = results[results[\"matches_prescription\"]].reset_index(drop=True)\n",
    "mismatches_df = results[~results[\"matches_prescription\"]].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3d3afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78db3af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mismatches_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c7a10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e87667b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mismatches_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c2249b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mismatches_df_confident = mismatches_df[mismatches_df[\"drug_expected\"].notna()]\n",
    "mismatches_df_confident.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90225300",
   "metadata": {},
   "source": [
    "This was a failure. I am not sure the idea is bad, but all of my mismatches are instances where I couldnt get a drug from the prescriptions table at all. This tells me I either have bad data or am not properly matching my extractions to the prescriptions table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea0d2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close() # sad :("
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
